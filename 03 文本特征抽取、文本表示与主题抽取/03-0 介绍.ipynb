{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本特征提取、文本表示和主题建模是自然语言处理（NLP）领域中的关键任务，它们有助于将文本数据转化为机器学习模型能够理解和处理的形式。以下是对这些概念的简要介绍以及当前主流方法的概述：\n",
    "\n",
    "1. **文本特征提取（Text Feature Extraction）**：\n",
    "   - **定义**：文本特征提取是将原始文本数据转换为可以用于机器学习模型的数值型特征的过程。\n",
    "   - **方法**：常见的文本特征提取方法包括<strong style=\"color:red;\">词袋模型（Bag of Words）</strong>、<strong style=\"color:red;\">TF-IDF（Term Frequency-Inverse Document Frequency）</strong>等。词袋模型将文本表示为词汇表中单词的计数向量，而TF-IDF则考虑了词在文本中的频率和在整个语料库中的重要性。\n",
    "\n",
    "2. **文本表示（Text Representation）**：\n",
    "   - **定义**：文本表示是将文本数据映射到连续向量空间的过程，以便机器学习模型能够更好地理解语义和上下文信息。\n",
    "   - **方法**：Word Embeddings（词嵌入）是目前最流行的文本表示方法之一。它通过训练神经网络将单词映射到低维连续向量，使得语义相近的单词在向量空间中距离较近。<strong style=\"color:red;\">Word2Vec</strong>、GloVe（Global Vectors for Word Representation）和FastText是常见的词嵌入方法。\n",
    "\n",
    "3. **主题建模（Topic Modeling）**：\n",
    "   - **定义**：主题建模是一种通过从文本中识别潜在主题来理解文本内容的方法。主题通常是一组相关的单词，代表文本中的概念或主要话题。\n",
    "   - **方法**：潜在语义分析（Latent Semantic Analysis，LSA）和<strong style=\"color:red;\">潜在狄利克雷分布（Latent Dirichlet Allocation，LDA）</strong>是两种常见的主题建模方法。LSA通过奇异值分解降维来捕捉语义信息，而LDA则使用贝叶斯模型从文档中推断主题分布。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
