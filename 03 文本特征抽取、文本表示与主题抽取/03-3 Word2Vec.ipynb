{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec 模型**\n",
    "\n",
    "Word2Vec 是一种用于将单词表示为向量的技术，它是自然语言处理（NLP）中的一个关键方法。该模型的目标是将语言中的词汇映射到高维向量空间，以便单词之间的语义关系能够在向量空间中得以保留。Word2Vec 模型是通过训练神经网络来学习单词嵌入（word embeddings）的一种方法。\n",
    "\n",
    "以下是一个使用 `gensim` 库实现 Word2Vec 模型的简单示例代码：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector representation of 'word': [-0.00536227  0.00236431  0.0510335   0.09009273 -0.0930295  -0.07116809\n",
      "  0.06458873  0.08972988 -0.05015428 -0.03763372]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 示例文本\n",
    "corpus = \"Word embeddings are a type of word representation that allows words to be represented as vectors in a continuous vector space.\"\n",
    "\n",
    "# 分词\n",
    "tokenized_text = word_tokenize(corpus.lower())  # 转为小写以保持一致性\n",
    "\n",
    "# 定义 Word2Vec 模型\n",
    "model = Word2Vec(sentences=[tokenized_text], vector_size=10, window=5, sg=0, min_count=1)\n",
    "\n",
    "# 获取单词向量\n",
    "word_vector = model.wv['word']\n",
    "\n",
    "# 打印单词向量\n",
    "print(\"Vector representation of 'word':\", word_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "在这个示例中：\n",
    "- `Word2Vec` 模型通过 `gensim` 库创建。\n",
    "- `vector_size` 参数定义了每个单词的向量维度。\n",
    "- `window` 参数定义了模型在训练时考虑的上下文窗口大小。\n",
    "- `sg` 参数表示使用 Skip-gram 模型（如果是 1）或 CBOW 模型（如果是 0）。\n",
    "- `min_count` 参数定义了在模型训练中忽略的最小词频。\n",
    "\n",
    "该模型通过训练神经网络，学习到了每个单词的向量表示。这些向量可以用于测量单词之间的相似性，执行词汇语义的数学运算，或作为更大 NLP 任务的输入。 Word2Vec 模型的训练需要大量文本数据，以便有效地捕捉词汇之间的复杂语义关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下是一些Word2Vec的主要应用场景：\n",
    "\n",
    "1. **自然语言处理任务改进**：Word2Vec生成的词嵌入可以用于提升各种自然语言处理任务的性能，如文本分类、命名实体识别、情感分析等。通过使用更具语义信息的词表示，模型可以更好地理解和捕捉文本中的语境。\n",
    "\n",
    "2. **相似度计算**：Word2Vec生成的词嵌入可以用于计算词之间的相似度。在信息检索、推荐系统等应用中，可以通过比较单词的向量表示来识别相似的词语，从而提供更准确的搜索结果或推荐。\n",
    "\n",
    "3. **语义关系分析**：Word2Vec的向量表示捕捉了单词之间的语义关系。通过在向量空间中执行向量运算，可以识别词语之间的语义关系，例如\"king - man + woman = queen\"这样的关系。\n",
    "\n",
    "4. **文本生成**：生成的词嵌入可以用于训练文本生成模型，如循环神经网络（RNN）或长短时记忆网络（LSTM）。这些模型可以生成更具语境和语义的文本。\n",
    "\n",
    "5. **词义消歧**：Word2Vec有助于处理词义消歧问题，即确定文本中单词的确切含义。通过比较单词的上下文信息，可以更好地理解单词在不同语境中的含义。\n",
    "\n",
    "6. **聚类分析**：基于Word2Vec生成的向量表示，可以对单词进行聚类分析，从而发现在语义上相关的词汇群组。\n",
    "\n",
    "总体而言，Word2Vec在许多NLP任务中都表现出色，并成为了自然语言处理领域中的一个重要工具。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
